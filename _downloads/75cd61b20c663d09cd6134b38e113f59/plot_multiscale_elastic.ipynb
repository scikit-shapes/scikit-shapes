{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Elastic metric and multiscale strategy\n\n\nThis examples is an implementation of the paper \"Geometric Modeling in Shape Space\"\nby Kilian, Mitra and Pottmann. More precisely, we implement the algorithm for the\nBoundary Value Problem, which is a registration between two shapes.\n\nThe framework proposed in the paper allows to find a deformation between two shapes\nthat minimizes an elastic metric. Optimizing directly the deformation in full\nresolution and with a large number of steps usually leads to bad local minima.\nTo avoid this, the authors propose a multiscale strategy, where the optimization\nis first performed in a coarse resolution and with a small number of steps. Then,\nrefinement can be done by increasing the resolution (space refinement) or the number\nof steps (time refinement).\n\nIn this example, we provide an implementation of the \"Boundary Value Problem\"\nalgorithm describe in section 3, using the as isometric as possible metric, defined\nat the end of section 2. The algorithm is applied to the registration of two elephant\nposes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pyvista as pv\nimport torch\n\nimport skshapes as sks\n\nsource_color = \"teal\"\ntarget_color = \"red\"\n\nsource = sks.PolyData(\"../test_data/elephants/pose_B.obj\")\ntarget = sks.PolyData(\"../test_data/elephants/pose_A.obj\")\n\n# Make sure that underlying simplicial complex are the same\ntriangles = source.triangles\ntarget.triangles = source.triangles\n\nplotter = pv.Plotter()\nplotter.add_mesh(source.to_pyvista(), color=source_color, label=\"source\")\nplotter.add_mesh(\n    target.to_pyvista().translate([250, 0, 0]),\n    color=target_color,\n    label=\"target\",\n)\nplotter.camera_position = [\n    (107.13691493781944, -436.8511227598446, 929.44474582162),\n    (138.38692092895508, -5.646553039550781, 2.4097938537597656),\n    (-0.07742352421458944, 0.9049853883599757, 0.41833843327279513),\n]\nplotter.add_legend()\nplotter.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define function for time refinement\n\nTime refinement is the process of doubling the number of steps of the model.\nFirst, parameter is augmented by linear interpolation between all the steps.\nThen, the registration model is refitted with the new parameter to minimize\nthe energy.\n\nIt is described in the section 3, paragraph \"The Boundary Value Problem\" of the paper.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lbfgs = sks.LBFGS()\n\n\ndef time_refinement(\n    parameter: torch.Tensor,\n    model: sks.BaseModel,\n    loss: sks.BaseLoss,\n    source: sks.PolyData,\n    target: sks.PolyData,\n    regularization_weight: float,\n    optimizer: sks.BaseOptimizer = lbfgs,\n    n_iter: int = 4,\n    gpu: bool = True,\n    verbose: bool = False,\n) -> tuple[torch.Tensor, sks.Registration, sks.BaseModel, list[sks.PolyData]]:\n    \"\"\"Double the number of steps by linear interpolation and refit the registration model.\n\n    Parameters\n    ----------\n    parameter\n        The parameter to refine.\n    model\n        The model used for the registration.\n    loss\n        The loss function.\n    source\n        The source shape.\n    target\n        The target shape.\n    regularization_weight\n        The regularization weight.\n    optimizer\n        The optimizer.\n    n_iter\n        The number of iterations.\n    gpu\n        Whether to use the GPU (if available).\n    verbose\n        Whether to print information during the process.\n    \"\"\"\n\n    # Copy the model\n    refined_model = model.copy()\n\n    # Double the number of steps by linear interpolation\n    # for the refined parameter\n    n_steps = parameter.shape[1]\n    if verbose:\n        print(\"Doubling the number of steps by linear interpolation...\")\n    n_steps = 2 * n_steps\n    new_parameter = torch.zeros(\n        (parameter.shape[0], n_steps, parameter.shape[2])\n    )\n    for i in range(parameter.shape[1]):\n        new_parameter[:, 2 * i, :] = parameter[:, i, :] / 2\n        new_parameter[:, 2 * i + 1, :] = parameter[:, i, :] / 2\n\n    # Update the model's n_steps and the regularization weight of the registration.\n    # note that the number of steps depends on the presence of fix endpoints\n    if model.endpoints is not None:\n        refined_model.n_steps = new_parameter.shape[1] + 1\n    else:\n        refined_model.n_steps = new_parameter.shape[1]\n\n    # Now, we can fit the refined parameter to minimize the energy\n    if verbose:\n        print(\"Optimizing the refined path wrt the metric...\")\n\n    registration = sks.Registration(\n        model=refined_model,\n        loss=loss,\n        optimizer=optimizer,\n        regularization_weight=regularization_weight,\n        verbose=verbose,\n        n_iter=n_iter,\n        gpu=gpu,\n    )\n\n    # Fit the refined parameter\n    registration.fit(\n        source=source, target=target, initial_parameter=new_parameter\n    )\n\n    return registration.parameter_, refined_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define function for Space refinement\n\nSpace refinement is the process of refining the path by projecting the points\nof the fine mesh on the coarse mesh.\n\nEach fine mesh can be projected to a coarse mesh,resulting in a system of\ncoordinates. The coordinates consist of (for each point of the fine mesh):\n\n* the id of the closer triangle in the coarse mesh\n* the barycentric coordinates of the point in the triangle (2 coordinates)\n* the orthogonal coordinate of the point with respect to the triangle normal\n\nWith this system of coordinate, a coarse mesh with the same triangles as the\none used to define the coordinates can be refined to a finer mesh. It is done\nby positioning points in the triangle of the coarse mesh and adding the orthogonal\ncoordinate to the position.\n\nThe space refinement process consists in:\n\n* projecting the fine source and target on the coarse source and target\n* refining the coarse sequence of poses to a fine sequence of poses for both systems of coordinates\n* defining the fine sequence as a linear combination of the two refined sequences\n\nThis step lead to a fine sequence of poses in at the fine resolution. The\nregistration model can then be refitted to minimize the energy.\n\nThis process is described in the section 3, paragraph \"The Boundary Value Problem\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from trimesh import Trimesh\nfrom trimesh.proximity import closest_point\nfrom trimesh.triangles import barycentric_to_points, points_to_barycentric\n\n\n@torch.no_grad\ndef compute_coordinates(\n    fine: sks.PolyData, coarse: sks.PolyData\n) -> tuple[sks.Int1dTensor, sks.Float2dTensor, sks.Float1dTensor]:\n    \"\"\"Compute coordinates of the fine points in the coarse mesh.\n\n    We follow the approach of \"Geometric Modeling in Shape Space\", the coordinates\n    are the id of the triangle, the 2D barycentric coordinates in the triangle\n    and the distance between the point and his projection in the normal direction.\n\n    Parameters\n    ----------\n    fine\n        The PolyData object of the fine mesh\n    coarse\n        The PolyData object of the coarse mesh\n\n    Returns\n    -------\n    tuple\n        The id of the triangle, the barycentric coordinates and the orthogonal coordinate\n        for each fine point.\n    \"\"\"\n\n    if not fine.n_points >= coarse.n_points:\n        msg = f\"The fine mesh should have more points than the coarse mesh, got {fine.n_points} and {coarse.n_points}\"\n        raise ValueError(msg)\n\n    faces = coarse.triangles.numpy()\n    vertices = coarse.points.numpy()\n\n    fine_points = fine.points.numpy()\n\n    mesh = Trimesh(vertices=vertices, faces=faces)\n\n    closest, distance, triangle_id = closest_point(\n        mesh=mesh, points=fine_points\n    )\n\n    triangle_id = torch.tensor(triangle_id, dtype=sks.int_dtype)\n    closest = torch.tensor(closest, dtype=sks.float_dtype)\n\n    assert triangle_id.shape == (fine.n_points,)\n    assert closest.shape == fine.points.shape\n\n    t = coarse.points[coarse.triangles[triangle_id]]\n\n    barycentric = points_to_barycentric(points=closest, triangles=t)\n\n    # descr = (triangle_id, barycentric, product with normal)\n\n    normals = coarse.triangle_normals / coarse.triangle_normals.norm(\n        dim=-1, keepdim=True\n    )\n\n    # p - p' = fine_points - closest\n    a = fine.points - closest\n\n    Ns = normals[triangle_id]\n\n    assert a.shape == Ns.shape\n\n    # scalar product\n    orthogonal_coordinate = (a * Ns).sum(dim=-1)\n\n    return triangle_id, barycentric, orthogonal_coordinate\n\n\n@torch.no_grad\ndef refine(coarse_mesh, coord_barycentric, triangle_id, orthogonal_coordinate):\n    \"\"\"Given a system of coordinates, refine the points in the origin mesh.\n\n    Parameters\n    ----------\n    coarse_mesh\n        The mesh to refine\n    coord_barycentric\n        The barycentric coordinates of the fine points\n    triangle_id\n        The id of the triangle in the coarse mesh for each fine point\n    orthogonal_coordinate\n        The orthogonal coordinate of the fine points with respect to the triangle normal\n\n    Returns\n    -------\n    sks.Points\n        The fine points\n    \"\"\"\n\n    Ns = coarse_mesh.triangle_normals[\n        triangle_id\n    ] / coarse_mesh.triangle_normals[triangle_id].norm(dim=-1, keepdim=True)\n\n    # Get the triangle\n    t = coarse_mesh.points[coarse_mesh.triangles[triangle_id]]\n\n    # Compute the orthogonal coordinate\n    orthogonal = orthogonal_coordinate.repeat(3, 1).T * Ns\n\n    # Compute the projection on the triangles\n    projections = barycentric_to_points(\n        barycentric=coord_barycentric, triangles=t\n    )\n    projections = torch.tensor(projections, dtype=sks.float_dtype)\n\n    return projections + orthogonal\n\n\ndef space_refinement(\n    coarse_source: sks.PolyData,\n    coarse_target: sks.PolyData,\n    fine_source: sks.PolyData,\n    fine_target: sks.PolyData,\n    coarse_model: sks.BaseModel,\n    coarse_parameter: torch.Tensor,\n    loss: sks.BaseLoss,\n    regularization_weight: float,\n    optimizer: sks.BaseOptimizer = lbfgs,\n    n_iter: int = 4,\n    gpu: bool = True,\n    verbose: bool = False,\n) -> tuple[torch.Tensor, sks.BaseModel]:\n    \"\"\"Refine the path following the space refinement strategy.\n\n    We start by refining the path from coarse to high resolution and then\n    optimize it with respect to the Riemannian metric (this optimization can\n    be disabled by setting n_iter=0)\n\n    The output is the parameter in the fine scale and the new model that can\n    be used later on for registration.\n\n    Parameters\n    ----------\n    coarse_source\n        The source shape in coarse resolution.\n    coarse_target\n        The target shape in coarse resolution.\n    fine_source\n        The source shape in fine resolution.\n    fine_target\n        The target shape in fine resolution.\n    coarse_model\n        The model in coarse resolution.\n    coarse_parameter\n        The parameter in coarse resolution.\n    loss\n        The loss object for the registration.\n    regularization_weight\n        The regularization weight.\n    optimizer\n        The optimizer.\n    n_iter\n        The number of iterations.\n    gpu\n        Whether to use the GPU (if available).\n    verbose\n        Whether to print information during the process.\n\n    Returns\n    -------\n        The parameter and the model in fine resolution.\n    \"\"\"\n\n    # Compute the path at coarse level\n    coarse_path = coarse_model.morph(\n        shape=coarse_source, parameter=coarse_parameter, return_path=True\n    ).path\n\n    # Copy the model\n    fine_model = coarse_model.copy()\n\n    if coarse_model.endpoints is not None:\n        fine_model.endpoints = fine_target.points\n\n    if verbose:\n        print(\"Projecting the fine meshes on the coarse meshes...\")\n\n    # Compute the coordinates of the fine points in the coarse meshes\n    (\n        triangle_id_source,\n        barycentric_coord_source,\n        orthogonal_coordinate_source,\n    ) = compute_coordinates(fine_source, coarse_source)\n    (\n        triangle_id_target,\n        barycentric_coord_target,\n        orthogonal_coordinate_target,\n    ) = compute_coordinates(fine_target, coarse_target)\n\n    fine_parameter = fine_model.inital_parameter(shape=fine_source)\n    print(fine_parameter.shape)\n    # fine_parameter = torch.zeros(size=(fine_source.n_points, fine_model.n_free_steps, 3), dtype=sks.float_dtype)\n\n    new_points = torch.zeros_like(fine_source.points, dtype=sks.float_dtype)\n    previous_points = torch.zeros_like(\n        fine_source.points, dtype=sks.float_dtype\n    )\n\n    if verbose:\n        print(\"Refining the path from coarse to fine...\")\n\n    for i, p in enumerate(coarse_path):\n\n        previous_points = new_points\n\n        if i == 0:\n            # Force the first point to be the source\n            new_points = fine_source.points\n\n        if i == len(coarse_path) - 1 and coarse_model.endpoints is not None:\n            # Force the last point to be the target\n            print(\"ok\")\n            new_points = fine_target.points\n            coarse_model.endpoints = fine_target.points\n\n        else:\n            newpoints_source = refine(\n                coarse_mesh=p,\n                coord_barycentric=barycentric_coord_source,\n                triangle_id=triangle_id_source,\n                orthogonal_coordinate=orthogonal_coordinate_source,\n            )\n\n            newpoints_target = refine(\n                coarse_mesh=p,\n                coord_barycentric=barycentric_coord_target,\n                triangle_id=triangle_id_target,\n                orthogonal_coordinate=orthogonal_coordinate_target,\n            )\n\n            new_points = ((i + 1) / len(coarse_path)) * newpoints_source + (\n                1 - (i + 1) / len(coarse_path)\n            ) * newpoints_target\n\n            fine_parameter[:, i - 1, :] = new_points - previous_points\n\n    if verbose:\n        print(\"Optimizing the fine path wrt the metric...\")\n\n    registration = sks.Registration(\n        model=fine_model,\n        loss=loss,\n        optimizer=optimizer,\n        n_iter=n_iter,\n        regularization_weight=regularization_weight,\n        verbose=verbose,\n        gpu=gpu,\n    )\n\n    registration.model = fine_model\n    registration.fit(\n        source=fine_source,\n        target=fine_target,\n        initial_parameter=fine_parameter,\n    )\n\n    return registration.parameter_, fine_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiscale representation\n\nBack to our example, we first decimate the source and target shapes to\na coarseer resolution. The decimation is done in parallel for both shapes to\nkeep the correspondence between the points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_points_coarse = 650\n\n# Parallel decimation of source and target\n# the same decimation module is used for creating the multiscale representation\n# of the source and target\ndecimation_module = sks.Decimation(n_points=650)\ndecimation_module.fit(source)\nn_points = [n_points_coarse]\n\nmultisource = sks.Multiscale(\n    source, n_points=n_points, decimation_module=decimation_module\n)\nmultitarget = sks.Multiscale(\n    target, n_points=n_points, decimation_module=decimation_module\n)\n\ncoarse_source = multisource.at(n_points=n_points_coarse)\ncoarse_target = multitarget.at(n_points=n_points_coarse)\nfine_source = multisource.at(n_points=source.n_points)\nfine_target = multitarget.at(n_points=target.n_points)\n\n# Plot the coarse source and target\nplotter = pv.Plotter()\nplotter.add_mesh(\n    coarse_source.to_pyvista(), color=source_color, label=\"coarse source\"\n)\nplotter.add_mesh(\n    coarse_target.to_pyvista().translate([250, 0, 0]),\n    color=target_color,\n    label=\"coarse target\",\n)\nplotter.camera_position = [\n    (107.13691493781944, -436.8511227598446, 929.44474582162),\n    (138.38692092895508, -5.646553039550781, 2.4097938537597656),\n    (-0.07742352421458944, 0.9049853883599757, 0.41833843327279513),\n]\nplotter.add_legend()\nplotter.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear blending in coarse resolution\n\nThe first path is obtained by a linear blending between the source and target\nshapes. The linear blending can be directly computed from the difference between\nthe source and target points. Here we use a registration with `IntrinsicDeformation`\nmodel and `L2Loss` loss with a regularization weight of 0.0. In this context, the\noptimal parameter is the linear blending between the source and target shapes.\n\nAs illustrated by the animation below, the linear blending is not satisfactory\nas the trunk of the elephant is shrunk in the middle of the path.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "registration = sks.Registration(\n    model=sks.IntrinsicDeformation(n_steps=10),\n    loss=sks.L2Loss(),\n    optimizer=sks.LBFGS(),\n    n_iter=3,\n    regularization_weight=0.0,\n)\n\nregistration.fit(source=coarse_source, target=coarse_target)\npath = registration.path_\nlinear_parameter = registration.parameter_\n\ncpos = [\n    (-180.28077332975926, -359.5814717933118, 468.17714455864336),\n    (23.941261291503906, -56.907809257507324, 2.4097938537597656),\n    (-0.06479680268614828, 0.8494856829410709, 0.5236176552025292),\n]\n\n\nplotter = pv.Plotter()\nplotter.open_gif(\"coarse_linear.gif\", fps=4)\nfor i in range(len(path)):\n    plotter.clear_actors()\n    plotter.add_mesh(source.to_pyvista(), color=source_color, opacity=0.1)\n    plotter.add_mesh(target.to_pyvista(), color=target_color, opacity=0.1)\n    plotter.add_mesh(path[i].to_pyvista())\n    plotter.camera_position = cpos\n    plotter.write_frame()\nplotter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## As isometric as possible registration in coarse resolution\n\nFollowing the remark at the end of section 2, we add additional edges to the source\nshape to make it stiffer. The choice of stiffener here is a k-ring graph with k=8.\nA k-ring graph is a graph where each vertex is connected to its k-nearest neighbors\nin the graph.\n\nThis additional rigidity helps to avoid the shrinkage of the trunk during the\ndeformation. As illustrated by the animation below, the registration is much\nmore satisfactory than the linear blending as the length of the trunk seems to\nbe preserved.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = sks.IntrinsicDeformation(n_steps=10, metric=\"as_isometric_as_possible\")\nloss = sks.L2Loss()\n\n\ncoarse_source.stiff_edges = coarse_source.k_ring_graph(k=8)\n\nregistration = sks.Registration(\n    model=model,\n    loss=loss,\n    optimizer=sks.LBFGS(),\n    n_iter=2,\n    regularization_weight=0.0001,\n    verbose=True,\n)\n\nregistration.fit(\n    source=coarse_source,\n    target=coarse_target,\n    initial_parameter=linear_parameter,\n)\npath = registration.path_\nparameter = registration.parameter_\n\nplotter = pv.Plotter()\nplotter.open_gif(\"coarse_isometric.gif\", fps=4)\nfor i in range(len(path)):\n    plotter.clear_actors()\n    plotter.add_mesh(source.to_pyvista(), color=source_color, opacity=0.1)\n    plotter.add_mesh(target.to_pyvista(), color=target_color, opacity=0.1)\n    plotter.add_mesh(path[i].to_pyvista())\n    plotter.camera_position = cpos\n    plotter.write_frame()\nplotter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time refinement\n\nAlthough better than the linear blending, the registration is not perfect. The\nmovement of the trunk is still not realistic. To improve the registration, we\napply a time refinement. Doubling the number of time steps increases flexibility\nat the price of a higher computational cost. However, the metric evaluation\nare typically not linear with the number of steps as we use pyTorch parallel\ncomputation as much as possible.\n\nAfter the time refinement, the deformation is much more realistic. The trunk\nis not shrunk anymore and the deformation is more natural. We can now move\non to the space refinement to obtain a deformation in full resolution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameter, model = time_refinement(\n    parameter=parameter,\n    model=model,\n    loss=loss,\n    source=coarse_source,\n    target=coarse_target,\n    regularization_weight=0.0001,\n    n_iter=3,\n    verbose=True,\n)\n\npath = model.morph(\n    shape=coarse_source, parameter=parameter, return_path=True\n).path\n\nplotter = pv.Plotter()\nplotter.open_gif(\"coarse_isometric_refined.gif\", fps=8)\nfor i in range(len(path)):\n    plotter.clear_actors()\n    plotter.add_mesh(source.to_pyvista(), color=source_color, opacity=0.1)\n    plotter.add_mesh(target.to_pyvista(), color=target_color, opacity=0.1)\n    plotter.add_mesh(path[i].to_pyvista())\n    plotter.camera_position = cpos\n    plotter.write_frame()\nplotter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Space refinement\n\nThe space refinement is the last step of our multiscale strategy. The path\nis refined from a coarse resolution where each mesh has 650 points to a fine\nresolution where each mesh has approximately 40k points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameter, model = space_refinement(\n    coarse_source=coarse_source,\n    coarse_target=coarse_target,\n    fine_source=fine_source,\n    fine_target=fine_target,\n    coarse_model=model,\n    loss=loss,\n    coarse_parameter=parameter,\n    regularization_weight=0.0001,\n    n_iter=1,\n    verbose=1,\n)\n\npath = model.morph(\n    shape=fine_source, parameter=parameter, return_path=True\n).path\n\nplotter = pv.Plotter()\nplotter.open_gif(\"fine_registration.gif\", fps=8)\nfor i in range(len(path)):\n    plotter.clear_actors()\n    plotter.add_mesh(source.to_pyvista(), color=source_color, opacity=0.1)\n    plotter.add_mesh(target.to_pyvista(), color=target_color, opacity=0.1)\n    plotter.add_mesh(path[i].to_pyvista())\n    plotter.camera_position = cpos\n    plotter.write_frame()\nplotter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remarks\n\nThis example illustrates the multiscale strategy proposed by Kilian, Mitra and\nPottmann. In the paper, the authors suggest strategies with more than two\nscales. The code written here can be easily adapted to deal with more intricate\nmultiscale strategies.\n\nAs a take-home message:\n\n* Register directly the shapes in full resolution is usually not a good idea\n* Coarse representation can be used to find a good initialization for the registration by adding stiffness to the shapes (e.g. with a k-ring graph)\n* Time refinement can be used to add flexibility to the deformation\n* When the coarse deformation is satisfactory, space refinement can be used to obtain a deformation in full resolution.\n\nFor future work, this strategy can be applied to more intricate problems such as\nthe registration of 3D shapes with different topologies (with varifold loss for\ninstance) or other metrics. The projection step in the space refinement can also\nbe improved by using a intrinsic metric to compute the coordinates of the fine\npoints in the coarse mesh instead of the Euclidean metric.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}